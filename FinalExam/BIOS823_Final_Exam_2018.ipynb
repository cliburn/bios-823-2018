{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOS 823 Final Exam (14 December 2018)\n",
    "\n",
    "- The time allocated is 3 hours\n",
    "- This is a **closed book** examination\n",
    "    - Close ALL applications on your laptop\n",
    "    - Start an empty browser with a SINGLE Tab in FULL SCREEN MODE\n",
    "    - You should only have this SINGLE notebook page open in your browser, with NO OTHER TABS or WINDOWS\n",
    "- You are not allowed any reference material except for the following:\n",
    "    - Cheat sheet (1 letter-sized paper, both sides)\n",
    "    - Built-in help accessible either by `?foo`, `foo?` or `help(foo)`\n",
    "- ALL necessary imports of Python modules have been done for you. \n",
    "- **You should not import any additional modules - this includes standard library packages**.\n",
    "\n",
    "The questions are worth a total of 120 points, but the maximum score is 100. Note that answers will be graded on **correctness**, **efficiency** and **readability**.\n",
    "\n",
    "<font color=blue>By taking this exam, you acknowledge that you have read the instructions and agree to abide by the Duke Honor Code.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**. (10 points)\n",
    "\n",
    "Warm up exercise.\n",
    "\n",
    "Find the 5 most common words and their counts in `data/moby.txt`, after removing punctuation, setting to lowercase and splitting by blank space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. (10 points)\n",
    "\n",
    "- Assemble the data from `features`, `subjects`, `X`, and `y` into a single `pandas.DataFrame (DF)` called `har`.  You should end up with a DF that is 7352 by 562 with `activity` as the first column. Rows and columns should be appropriately labeled.\n",
    "    - `X` is a matrix where each row is a feature matrix\n",
    "    - The columns of X are given in `features`\n",
    "    - Each row of X is a subject given in `subjects`\n",
    "    - `y` is a code for the type of activity performed by the subject (name the column in the DataFrame `actvitity`)\n",
    "- Name the index `subject`\n",
    "- Display a sample of 5 rows chosen at random without replacement and the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = np.loadtxt('data/HAR/activity_labels.txt', dtype='str')\n",
    "features = np.loadtxt('data/HAR/features.txt', dtype='str')[:, 1]\n",
    "subjects = np.loadtxt('data/HAR/train/subject_train.txt', dtype='int')\n",
    "X = np.loadtxt('data/HAR/train/X_train.txt')\n",
    "y = np.loadtxt('data/HAR/train/y_train.txt', dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. (10 points)\n",
    "\n",
    "Using the DF from Question 1, find the average feature value for each subject for all features that have the string `entropy` in it but does NOT end in X, Y or Z. Use method chaining to perform this operation and show a random sample of 5 rows without replacement as a single expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. (10 points)\n",
    "\n",
    "Write an SQL query against the `har` table to count the number of distinct subjects and the total number of rows for each activity, ordering the results by number of rows for each activity in decreasing order. A simple example of how to run an SQL query using `pandas` is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///data/har.db', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT subject, activity \n",
    "FROM har \n",
    "LIMIT 5\n",
    "'''\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5**. (25 points)\n",
    "\n",
    "- Create a new DF `df` from the `har` DF with all features that include the string `Acc-mean`\n",
    "- Scale the feature columns so that all features have mean 0 and standard deviation 1\n",
    "- Use SVD to find the first two principal components\n",
    "- Plot the first two principal components as a scatter plot colored by the `activity` type of each feature vector\n",
    "- Plot the 2D t-SNE plot colored in the same way (t-SNE dimension reduction may take 1-2 minutes)\n",
    "\n",
    "Do not import any other packages apart from the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = np.loadtxt('data/HAR/test/X_test.txt')\n",
    "y_test_data = np.loadtxt('data/HAR/test/y_test.txt', dtype='int')\n",
    "subjects_test = np.loadtxt('data/HAR/test/subject_test.txt', dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. (25 points)\n",
    "\n",
    "You are given training and test data and labels using a subset of the HAR data set. Your job is to use these features to classify rows into WALKING UPSTAIRS (code = 2) or WALKING DOWNSTAIRS (code = 3). \n",
    "\n",
    "- Scale the data to have mean zero and unit standard deviation using `StandardScaler`, taking care to apply the same scaling parameters for the training and test data sets\n",
    "- Use the LaeblEncoder to transform the codes 2 and 3 to 0 and 1 in `y_train` and `y_test` \n",
    "- Perform ridge regression to classify data as WALKING UPSTAIRS or WALKING DOWNSTAIRS\n",
    "    - Train the model with an Cs value chosen from one of (0.01, 0.1, 1, 10, 100) by 5-fold cross-validation using the training data\n",
    "    - Plot the ROC curve (TPR versus FPR) evaluated on the test data\n",
    "\n",
    "The necessary classes from `sklearn` are imported for you. Do not use any other `sklearn` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/X_train.npy')\n",
    "X_test = np.load('data/X_test.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7**. (30 points)\n",
    "\n",
    "- Make the `kmeans` function given below by using Cython. A simple example is given as a hint.\n",
    "- Find the speed-up of the Cython version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cython example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "def foo(X):\n",
    "    \"\"\"Python function.\"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "    s = 0.0\n",
    "    for i in range(n):\n",
    "        s += square(X[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "import cython\n",
    "from libc.math cimport pow\n",
    "\n",
    "cdef double square_cython(double x):\n",
    "    return pow(x, 2)\n",
    "\n",
    "@cython.wraparound(False)\n",
    "@cython.boundscheck(False)\n",
    "def foo_cython(double[:] X):\n",
    "    \"\"\"Cython function.\"\"\"\n",
    "\n",
    "    cdef int n = X.shape[0]\n",
    "    cdef double s = 0.0\n",
    "    \n",
    "    cdef int i\n",
    "    \n",
    "    for i in range(n):\n",
    "        s += square_cython(X[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(np.arange(10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_cython(np.arange(10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm to Cythonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdist(X, Y):\n",
    "    \"\"\"Matrix of Euclidean distances between vectors in X and vectors in Y.\"\"\"\n",
    "    \n",
    "    m, p = X.shape\n",
    "    n, p = Y.shape\n",
    "    M = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            d = 0\n",
    "            for k in range(p):\n",
    "                d += (X[i,k] - Y[j,k])**2\n",
    "            M[i, j] = np.sqrt(d)\n",
    "    return M        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kemans(X, k, iters=10):\n",
    "    \"\"\"K-means with fixed number of iterations.\"\"\"\n",
    "\n",
    "    r, c = X.shape\n",
    "    centers = X[:k]\n",
    "    for i in range(iters):\n",
    "        m = cdist(X, centers)\n",
    "        z = np.argmin(m, axis=1)\n",
    "        centers = np.array([np.mean(X[z==i], axis=0) for i in range(k)])\n",
    "    return (z, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2017)\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "npts = 10000\n",
    "nc = 6\n",
    "X, y = make_blobs(n_samples=npts, centers=nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, centers = kemans(X, nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], s=5, c=z,\n",
    "            cmap=plt.cm.get_cmap('Accent', nc))\n",
    "plt.scatter(centers[:, 0], centers[:, 1], marker='x',\n",
    "            linewidth=3, s=100, c='red')\n",
    "plt.axis('square')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
